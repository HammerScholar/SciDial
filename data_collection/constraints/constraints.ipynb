{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acronym': ['ACL', 'EMNLP'],\n",
       " 'year': ['今年', '2022', '去年', '近两年'],\n",
       " 'fullName': ['XXX'],\n",
       " 'paperDue': ['XXX',\n",
       "  '最近一个月',\n",
       "  '最近',\n",
       "  '快要',\n",
       "  '要',\n",
       "  '下周',\n",
       "  '下下个月',\n",
       "  '下个月',\n",
       "  '下一个月',\n",
       "  '这几天',\n",
       "  '11月份',\n",
       "  '已经'],\n",
       " 'noticeDue': ['XXX',\n",
       "  '最近一个月',\n",
       "  '最近',\n",
       "  '快要',\n",
       "  '要',\n",
       "  '下周',\n",
       "  '下下个月',\n",
       "  '下个月',\n",
       "  '下一个月',\n",
       "  '这几天',\n",
       "  '11月份',\n",
       "  '已经'],\n",
       " 'heldDate': ['XXX',\n",
       "  '最近一个月',\n",
       "  '最近',\n",
       "  '快要',\n",
       "  '要',\n",
       "  '下周',\n",
       "  '下下个月',\n",
       "  '下个月',\n",
       "  '下一个月',\n",
       "  '这几天',\n",
       "  '11月份',\n",
       "  '已经'],\n",
       " 'abstractDue': ['XXX', '11月份', '马上要', '最近要', '下个月', '已经'],\n",
       " 'finalDue': ['XXX', '11月份', '马上要', '最近要', '最近', '下个月', '已经'],\n",
       " 'location': ['XXX', '北京', '线上', '线下', '网上'],\n",
       " 'category': ['XXX', 'NLP', '人工智能'],\n",
       " 'ccf': ['XXX', 'A类', 'B类'],\n",
       " 'website': ['XXX', 'https://www.2022.aclweb.org/', 'https://www.nature.com/'],\n",
       " 'bestPaper': ['XXX'],\n",
       " 'confRelated': ['XXX'],\n",
       " 'journalRelated': ['XXX'],\n",
       " 'doi': ['XXX'],\n",
       " 'title': ['这篇论文', 'Attention is all you need', 'Generative Adversarial Nets'],\n",
       " 'author': ['李航', '黄河燕', '毛先领'],\n",
       " 'venue': ['ACL', 'EMNLP'],\n",
       " 'institution': ['北京大学', '清华大学'],\n",
       " 'abstract': ['XXX'],\n",
       " 'pdf': ['XXX',\n",
       "  'https://aclanthology.org/2020.lrec-1.53.pdf',\n",
       "  'https://arxiv.org/pdf/2110.07679.pdf'],\n",
       " 'blog': ['XXX'],\n",
       " 'path': ['XXX', '桌面'],\n",
       " 'name': ['TOIS', 'TKDE', 'NATURE', '李航', '黄河燕', '北京大学'],\n",
       " 'ISSN': ['XXX'],\n",
       " 'E_ISSN': ['XXX'],\n",
       " 'IF': ['XXX', 'IF>10', 'IF>15', 'IF大于10', 'IF最高', 'IF指标最高', 'IF指标不是最高'],\n",
       " 'h_index': ['XXX',\n",
       "  'h5>10',\n",
       "  'h5>15',\n",
       "  'h5最高',\n",
       "  'h5大于10',\n",
       "  'h5指标最高',\n",
       "  'h5指标不是最高',\n",
       "  'h5指标好像不是最高'],\n",
       " 'self_citing': ['XXX', '自引率最高'],\n",
       " 'sci': ['XXX', 'SCI一区', 'sci一区'],\n",
       " 'submit': ['XXX'],\n",
       " 'speed': ['XXX'],\n",
       " 'rate': ['XXX'],\n",
       " 'field': ['XXX', 'NLP', '人工智能', '自然语言处理', '机器翻译'],\n",
       " 'affiliation': ['北京大学', '清华大学', '北京理工大学'],\n",
       " 'position': ['XXX', '副教授', '教授'],\n",
       " 'citations': ['XXX'],\n",
       " 'pubs': ['XXX'],\n",
       " 'address': ['XXX']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模板槽值默认值\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from static import annotate_db\n",
    "annotate_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查annotate_db是否全了\n",
    "import json\n",
    "with open(\"../annotate/user_template.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    user=json.load(fw)\n",
    "with open(\"../annotate/system_template.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    system=json.load(fw)\n",
    "\n",
    "for _, i in user.items():\n",
    "    required_slot = i[\"required_slot\"]\n",
    "    for slot in required_slot:\n",
    "        if slot==\"OA\":\n",
    "            continue\n",
    "        if \"Doubt\" in i[\"action\"][0]:\n",
    "            continue\n",
    "        if i[\"action\"][0]==\"Paper-Download\" and slot in [\"title\", \"pdf\"]:\n",
    "            continue\n",
    "        for k in i[\"message\"]:\n",
    "            value = None\n",
    "            for j in annotate_db[slot]:\n",
    "                if j in k:\n",
    "                    value = j\n",
    "                    break\n",
    "            if value is None:\n",
    "                print(k, annotate_db[slot],slot,i[\"action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间模板数: 1406\n"
     ]
    }
   ],
   "source": [
    "# 生成data.json\n",
    "import json\n",
    "time_candidate=[]\n",
    "for year in range(2010, 2024): # XX年\n",
    "    t=[(year,1,1), (year,12,31), \"%d年\" % year]\n",
    "    time_candidate.append(t)\n",
    "for year in [2022, 2023]: # 一个月时间段\n",
    "    for month in range(1,13):\n",
    "        # 一个月\n",
    "        t=[(year,month,1), (year,month,31), \"%d年%d月\" % (year,month)]\n",
    "        time_candidate.append(t)\n",
    "        # # 两个月\n",
    "        # if month<12:\n",
    "        #     t=[(year,month,1), (year,month+1,31), \"从%d年%d月到%d月\" % (year,month,month+1), \"%d年%d月和%d月\" % (year,month,month+1)]\n",
    "        # else:\n",
    "        #     t=[(year,month,1), (year+1,month,31), \"从%d年%d月到%d年%d月\" % (year,month,year+1,1), \"%d年%d月和%d年%d月\" % (year,month,year,1)]\n",
    "        # time_candidate.append(t)\n",
    "for year in [2021, 2022, 2023]:\n",
    "    # 三个月            \n",
    "    if month<11:\n",
    "        t=[(year,month,1), (year,month+2,31), \"从%d年%d月到%d月\" % (year,month,month+2)]\n",
    "    else:\n",
    "        t=[(year,month,1), (year+1,(month+2)%12,31), \"从%d年%d月到%d年%d月\" % (year,month,year+1,(month+2)%12)]\n",
    "    time_candidate.append(t)\n",
    "\n",
    "months = [i for i in range(11,13)]\n",
    "days = [0,31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "time = [(x,i,y,j) for x in months for y in months for i in range(1,days[x]+1) for j in range(1,days[x]+1)]\n",
    "for t in time: # 2022年XX月XX日到XX月XX日\n",
    "    if t[0]<t[2]:\n",
    "        x=[(2022,t[0],t[1]), (2022,t[2],t[3]), \"从%d月%d号到%d月%d号\" % (t[0],t[1],t[2],t[3])]\n",
    "        time_candidate.append(x)\n",
    "    elif t[0]==12 and t[0]==t[2] and t[1]<t[3]:\n",
    "        x=[(2022,t[0],t[1]), (2022,t[2],t[3]), \"从%d月%d号到%d号\" % (t[0],t[1],t[3])]\n",
    "        time_candidate.append(x)\n",
    "\n",
    "print(\"时间模板数:\", len(time_candidate))\n",
    "with open(\"date.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "result=[]\n",
    "# 结合之前的人工标注填入值\n",
    "for time in time_candidate:\n",
    "    value = time\n",
    "    for i in data:\n",
    "        if time[0][0]==i[0][0] and time[0][1]==i[0][1] and time[0][2]==i[0][2] and time[1][0]==i[1][0] and time[1][1]==i[1][1] and time[1][2]==i[1][2]:\n",
    "            value1, value2 = time[2:], i[2:]\n",
    "            value += list(set(value2) - set(value1))\n",
    "            break\n",
    "    result.append(value)\n",
    "    \n",
    "with open(\"z.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(result,fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并date.json中相同时间段\n",
    "import json\n",
    "with open(\"date.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "days = [0,31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "result = {}  # 相同slot合并\n",
    "for i in data:\n",
    "    start,end = i[0],i[1]\n",
    "    start[2]=days[start[1]] if start[2]>days[start[1]] else start[2]\n",
    "    end[2]=days[end[1]] if end[2]>days[end[1]] else end[2]\n",
    "    key = \"%d-%d-%d %d-%d-%d\" % (start[0],start[1],start[2],end[0],end[1],end[2])\n",
    "    if key in result.keys():\n",
    "        result[key].extend(i[2:])\n",
    "    else:\n",
    "        result[key] = i\n",
    "d = [j for _,j in result.items()]\n",
    "with open(\"date.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(d,fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成location.json\n",
    "import jieba\n",
    "import re\n",
    "import json\n",
    "with open(\"../dataset/db_process/conference_db.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "location={}\n",
    "for i in data:\n",
    "    pattern = re.compile(r'[a-zA-Z]+|[,，&的\\s]|-|（.*）')\n",
    "    i[\"location\"]=re.sub(pattern, \"\", i[\"location\"])\n",
    "    seg_list=jieba.cut(i[\"location\"], cut_all=False)\n",
    "    for j in seg_list:\n",
    "        country=j\n",
    "        break\n",
    "    if i[\"location\"] == \"\":\n",
    "        continue\n",
    "    elif i[\"location\"] not in location.keys():\n",
    "        location[i[\"location\"]] = 1\n",
    "    else:\n",
    "        location[i[\"location\"]] += 1\n",
    "    if country == \"\":\n",
    "        continue\n",
    "    elif country not in location.keys():\n",
    "        location[country] = 1\n",
    "    else:\n",
    "        location[country] += 1\n",
    "location = sorted(location.items(),key=lambda x:x[1],reverse=True)\n",
    "location = [i[0] for i in location[:29]]\n",
    "with open(\"location.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(location,fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成category.json\n",
    "import re\n",
    "with open(\"../dataset/db_process/conference_db.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "category = {}\n",
    "pattern = re.compile(r'[0-9一的（），,司或坐]')\n",
    "for i in data:\n",
    "    for j in i[\"category\"]:\n",
    "        if re.search(pattern,j) is not None:\n",
    "            continue\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        if j not in category.keys():\n",
    "            category[j] = 1\n",
    "        else:\n",
    "            category[j] += 1\n",
    "category = sorted(category.items(),key=lambda x:x[1],reverse=True)\n",
    "category = [i[0] for i in category[:29]]\n",
    "with open(\"conf_category.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(category,fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成venue.json、author.json、paper_institution.json\n",
    "with open(\"../dataset/db_process/paper_db.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "author = {}\n",
    "institution = {}\n",
    "venue = {}\n",
    "for i in data:\n",
    "    if i[\"venue\"] != \"\":\n",
    "        if i[\"venue\"] not in venue.keys():\n",
    "            venue[i[\"venue\"]] = 1\n",
    "        else:\n",
    "            venue[i[\"venue\"]] += 1\n",
    "    for j in i[\"author\"]:\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        if j not in author.keys():\n",
    "            author[j] = 1\n",
    "        else:\n",
    "            author[j] += 1\n",
    "    for j in i[\"institution\"]:\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        if j not in institution.keys():\n",
    "            institution[j] = 1\n",
    "        else:\n",
    "            institution[j] += 1\n",
    "author = sorted(author.items(),key=lambda x:x[1],reverse=True)\n",
    "author = [i[0] for i in author if i[1]>=100]\n",
    "venue = sorted(venue.items(),key=lambda x:x[1],reverse=True)\n",
    "venue = [i[0] for i in venue if i[1]>=100]\n",
    "institution = sorted(institution.items(),key=lambda x:x[1],reverse=True)\n",
    "institution = [i[0] for i in institution if i[1]>=100]\n",
    "\n",
    "with open(\"venue.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(venue,fw,indent=4,ensure_ascii=False)\n",
    "with open(\"author.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(author,fw,indent=4,ensure_ascii=False)\n",
    "with open(\"paper_institution.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(institution,fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成journal_category.json\n",
    "with open(\"../dataset/db_process/journal_db.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "category = {}\n",
    "for i in data:\n",
    "    if i[\"category\"] == \"\":\n",
    "        continue\n",
    "    if i[\"category\"] not in category.keys():\n",
    "        category[i[\"category\"]] = 1\n",
    "    else:\n",
    "        category[i[\"category\"]] += 1\n",
    "\n",
    "with open(\"journal_category.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(list(category.keys()),fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成field.json、affiliation.json、position.json\n",
    "with open(\"../dataset/db_process/author_db.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    data=json.load(fw)\n",
    "field = {}\n",
    "affiliation = {}\n",
    "position = []\n",
    "for i in data:\n",
    "    if i[\"position_zh\"] != \"\" and i[\"position_zh\"] not in position:\n",
    "        position.append(i[\"position_zh\"])\n",
    "    for j in i[\"field\"]:\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        if j not in field.keys():\n",
    "            field[j] = 1\n",
    "        else:\n",
    "            field[j] += 1\n",
    "    for j in i[\"affiliation\"]:\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        if j not in affiliation.keys():\n",
    "            affiliation[j] = 1\n",
    "        else:\n",
    "            affiliation[j] += 1\n",
    "field = sorted(field.items(),key=lambda x:x[1],reverse=True)\n",
    "field = [i[0] for i in field[:30]]\n",
    "affiliation = sorted(affiliation.items(),key=lambda x:x[1],reverse=True)\n",
    "affiliation = [i[0] for i in affiliation if i[1]>1]\n",
    "\n",
    "with open(\"field.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(field,fw,indent=4,ensure_ascii=False)\n",
    "with open(\"affiliation.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(affiliation,fw,indent=4,ensure_ascii=False)\n",
    "with open(\"position.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(position,fw,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccf\n",
    "ccf = [\"A类\", \"B类\", \"C类\", \"B类以上\", \"B类以下\",  \"C类以上\", \"A类以下\", \"ccf-a\", \"ccf-b\", \"ccf-c\", \"ccf a\", \"ccf b\", \"ccf c\", \"ccfA\", \"ccfB\", \"ccfC\"]\n",
    "sci = [\"sci 1区\", \"sci 2区\", \"sci 3区\", \"sci 4区\", \"sci1区\", \"sci2区\", \"sci3区\", \"sci4区\", \"1区\", \"2区\", \"3区\", \"4区\"]\n",
    "year = [\"今年\", \"去年\", \"前年\", \"2022\", \"2021\", \"2020\", \"2019\", \"2018\", \"2017\", \"2016\", \"2015\", \"2014\", \"2013\", \"2012\", \"2011\", \"2010\", \"2009\", \"2008\", \"2007\", \"2006\", \"2005\", \"2004\", \"2003\", \"2002\", \"2001\", \"2022年\", \"2021年\", \"2020年\", \"2019年\", \"2018年\", \"2017年\", \"2016年\", \"2015年\", \"2014年\", \"2013年\", \"2012年\", \"2011年\", \"2010年\", \"2009年\", \"2008年\", \"2007年\", \"2006年\", \"2005年\", \"2004年\", \"2003年\", \"2002年\", \"2001年\"]\n",
    "OA = [\"可以开放访问\", \"不可以开放访问\", \"禁止访问\"]\n",
    "# if h_index\n",
    "IF=['IF大于1', 'IF>1', 'IF影响因子大于1', 'IF影响因子>1', 'IF大于2', 'IF>2', 'IF影响因子大于2', 'IF影响因子>2', 'IF大于3', 'IF>3', 'IF影响因子大于3', 'IF影响因子>3', 'IF大于4', 'IF>4', 'IF影响因子大于4', 'IF影响因子>4', 'IF大于5', 'IF>5', 'IF影响因子大于5', 'IF影响因子>5', 'IF大于6', 'IF>6', 'IF影响因子大于6', 'IF影响因子>6', 'IF大于7', 'IF>7', 'IF影响因子大于7', 'IF影响因子>7', 'IF大于8', 'IF>8', 'IF影响因子大于8', 'IF影响因子>8', 'IF大于9', 'IF>9', 'IF影响因子大于9', 'IF影响因子>9', 'IF大于10', 'IF>10', 'IF影响因子大于10', 'IF影响因子>10']\n",
    "h_index=['h指数大于10', 'h指数>10', 'h5指数大于10', 'h5指数>10', 'h指数大于20', 'h指数>20', 'h5指数大于20', 'h5指数>20', 'h指数大于30', 'h指数>30', 'h5指数大于30', 'h5指数>30', 'h指数大于40', 'h指数>40', 'h5指数大于40', 'h5指数>40', 'h指数大于50', 'h指数>50', 'h5指数大于50', 'h5指数>50', 'h指数大于60', 'h指数>60', 'h5指数大于60', 'h5指数>60', 'h指数大于70', 'h指数>70', 'h5指数大于70', 'h5指数>70', 'h指数大于80', 'h指数>80', 'h5指数大于80', 'h5指数>80', 'h指数大于90', 'h指数>90', 'h5指数大于90', 'h5指数>90', 'h指数大于100', 'h指数>100', 'h5指数大于100', 'h5指数>100']\n",
    "# IF, h_index=[],[]\n",
    "# for i in range(1,11):\n",
    "#     num = str(i)\n",
    "#     num1 = str(i*10)\n",
    "#     IF += [\"IF大于\"+num,\"IF>\"+num,\"IF影响因子大于\"+num,\"IF影响因子>\"+num]\n",
    "#     h_index += [\"h指数大于\"+num1,\"h指数>\"+num1,\"h5指数大于\"+num1,\"h5指数>\"+num1]\n",
    "# print(IF)\n",
    "# print(h_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将除date外合并到constraints.json中\n",
    "import json\n",
    "dict = {\n",
    "    \"Conference\": {},\n",
    "    \"Paper\": {},\n",
    "    \"Journal\": {},\n",
    "    \"Author\": {}\n",
    "}\n",
    "# with open(\"constraints/date.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "#     dict[\"Conference\"][\"date\"] = json.load(fw)\n",
    "with open(\"constraints/location.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Conference\"][\"location\"] = json.load(fw)\n",
    "with open(\"constraints/conf_category.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Conference\"][\"category\"] = json.load(fw)\n",
    "dict[\"Conference\"][\"ccf\"]=ccf\n",
    "with open(\"constraints/author.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Paper\"][\"author\"] = json.load(fw)\n",
    "with open(\"constraints/paper_institution.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Paper\"][\"institution\"] = json.load(fw)\n",
    "with open(\"constraints/venue.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Paper\"][\"venue\"] = json.load(fw)\n",
    "dict[\"Paper\"][\"year\"] = year\n",
    "dict[\"Journal\"][\"IF\"] = IF\n",
    "dict[\"Journal\"][\"h_index\"] = h_index\n",
    "dict[\"Journal\"][\"ccf\"] = ccf\n",
    "dict[\"Journal\"][\"sci\"] = sci\n",
    "dict[\"Journal\"][\"OA\"] = OA\n",
    "with open(\"constraints/journal_category.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Journal\"][\"category\"] = json.load(fw)\n",
    "with open(\"constraints/field.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Author\"][\"field\"] = json.load(fw)\n",
    "with open(\"constraints/affiliation.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Author\"][\"affiliation\"] = json.load(fw)\n",
    "with open(\"constraints/position.json\", \"r\", encoding=\"utf-8\") as fw:\n",
    "    dict[\"Author\"][\"position\"] = json.load(fw)\n",
    "# 写入\n",
    "with open(\"constraints.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(dict,fw,indent=4,ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54f4cf6af044592288187f397fb324841d4c83addf22e4a134cd1393f3cb0b77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
